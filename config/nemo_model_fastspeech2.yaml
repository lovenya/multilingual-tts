# config/nemo_model_config.yaml
phoneme_vocab_size: 134            # number based on the output of generate_phoneme_inventory.py
phoneme_embedding_dim: 256         # This will be loaded from a pre-trained checkpoint if available.
language_vocab_size: 4             # For {en, gu, bh, kn}
language_embedding_dim: 32
speaker_vocab_size: 8              # 8 speakers in the current dataset
speaker_embedding_dim: 32
hidden_size: 512
n_layers: 4
n_heads: 8
dropout: 0.1
mel_dim: 80                      # Mel-spectrogram channels
# Optional: path to pre-trained phoneme embedding weights (if available)
# pretrained_phoneme_embedding_path: "checkpoints/pretrained_phoneme_emb.pt"
